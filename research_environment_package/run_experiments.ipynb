{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100f092c",
   "metadata": {},
   "source": [
    "# Research Environment Experiments\n",
    "\n",
    "This notebook demonstrates how to use the research environment and agents to run experiments, evaluate performance and accuracy, and generate comparison plots.  It mirrors the functionality of the `run_experiments.py` script supplied in the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc181a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the research environment and agents\n",
    "from research_env import ResearchEnv\n",
    "from agents import QLearningAgent, SFAgent, BAMDPSRAgent\n",
    "from experiment import run_experiment, evaluate_accuracy, plot_metrics\n",
    "\n",
    "# Create a drifting environment (context may switch once per episode)\n",
    "env = ResearchEnv(n_states=6, n_actions=2, drift_in_episode=True)\n",
    "\n",
    "# Training parameters\n",
    "n_episodes = 200\n",
    "max_steps = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9903075",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train Q-learning agent\n",
    "results = {}\n",
    "results['Q-learning'] = run_experiment(env, QLearningAgent, n_episodes, max_steps, {\n",
    "    'alpha': 0.1, 'epsilon': 0.1, 'gamma': 0.95\n",
    "})\n",
    "\n",
    "# Train successor-feature agent\n",
    "results['Successor Features'] = run_experiment(env, SFAgent, n_episodes, max_steps, {\n",
    "    'alpha_sr': 0.3, 'alpha_w': 0.3, 'gamma': 0.95, 'epsilon': 0.1\n",
    "})\n",
    "\n",
    "# Train adaptive SR agent with drift controller\n",
    "results['Adaptive SR'] = run_experiment(env, BAMDPSRAgent, n_episodes, max_steps, {\n",
    "    'alpha_sr': 0.2, 'alpha_w': 0.2, 'alpha_t': 0.05,\n",
    "    'gamma': 0.95, 'drift_alpha': 1.0, 'drift_beta': 1.0,\n",
    "    'drift_threshold': 0.5, 'explore_steps': 3\n",
    "})\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec1b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate accuracy and average returns on a static environment (no drift)\n",
    "eval_env = ResearchEnv(n_states=6, n_actions=2, drift_in_episode=False)\n",
    "accuracies = {}\n",
    "for name, res in results.items():\n",
    "    agent = res['agent']\n",
    "    avg_ret = agent.evaluate(n_episodes=30, max_steps=max_steps)\n",
    "    acc = evaluate_accuracy(eval_env, agent, n_episodes=30, max_steps=max_steps)\n",
    "    accuracies[name] = acc\n",
    "    print(f\"{name}: average return = {avg_ret:.3f}, accuracy = {acc:.3f}\")\n",
    "\n",
    "# Plot metrics (smoothed returns, training times and accuracies)\n",
    "plot_metrics(results, accuracies, smoothing=10)\n",
    "\n",
    "print(\"Comparison plot saved as comparison_metrics.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c26c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To interactively explore the environment, uncomment and run the following line.\n",
    "# Note: this requires input from the user in each cell.\n",
    "# from experiment import interactive_env_demo\n",
    "# interactive_env_demo(env, n_steps=10)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
